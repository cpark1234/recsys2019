{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "impression_embed_size = 50 # 853,540개 \n",
    "poi_embed_size = 50      # 13,352개\n",
    "filter_embed_size = 50   # 208개\n",
    "platform_embed_size = 5       # 55개\n",
    "city_embed_size = 50          # 34,752개\n",
    "sort_embed_size = 50 #interaction 빼고 one-hot\n",
    "device_embed_size = 3 # mobile, desktop, tablet one-hot\n",
    "\n",
    "rnn_input_size = impression_embed_size + 5 # action 5개로 통합 후 one-hot \n",
    "\n",
    "#LSTM\n",
    "hidden_state_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "seq_length = 10\n",
    "num_epoch = 10\n",
    "batch_size = 1\n",
    "\n",
    "input_size = 100 # TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Act_list = tf.placeholder(tf.string, [None, seq_length])\n",
    "Ref_list = tf.placeholder(tf.string, [None, seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functions as f\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "meta_df = pd.read_csv('./item_metadata.csv')\n",
    "submit_df = pd.read_csv('./submission_popular.csv')\n",
    "\n",
    "popular_df = f.get_popularity(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ecube_server2/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "poi_idx = np.load('./npy/poi_names.npy', allow_pickle=True)\n",
    "poi_idx = list(poi_idx)\n",
    "impressions_idx = np.load('./npy/impressions_index.npy', allow_pickle=True)\n",
    "impressions_idx = list(impressions_idx)\n",
    "city_idx = np.load('./npy/city_names.npy', allow_pickle=True)\n",
    "city_idx = list(city_idx)\n",
    "platform_idx = np.load('./npy/platform_names.npy', allow_pickle=True)\n",
    "platform_idx = list(platform_idx)\n",
    "filter_idx = np.load('./npy/filter_merged.npy', allow_pickle=True)\n",
    "filter_idx = list(filter_idx)\n",
    "action_idx = np.load('./npy/action_type_names.npy', allow_pickle=True)\n",
    "action_idx = list(action_idx)\n",
    "\n",
    "sort_order_idx = np.load('./npy/sorting_names.npy', allow_pickle=True)\n",
    "sort_order_idx = list(sort_order_idx)\n",
    "device_idx = np.load('./npy/device_names.npy', allow_pickle=True)\n",
    "device_idx = list(device_idx)\n",
    "\n",
    "poi_embedding = tf.get_variable(\"poi_embedding\", [len(poi_idx), poi_embed_size])\n",
    "impression_embedding = tf.get_variable(\"impression_embedding\", [len(impressions_idx), impression_embed_size])\n",
    "city_embedding = tf.get_variable(\"city_embedding\", [len(city_idx), city_embed_size])\n",
    "platform_embedding = tf.get_variable(\"platform_embedding\", [len(platform_idx), platform_embed_size])\n",
    "filter_embedding = tf.get_variable(\"filter_embedding\", [len(filter_idx), filter_embed_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_df[(train_df[\"action_type\"] == \"clickout item\")]     #train_label : (1,586,586, 12)\n",
    "batch_indexes = np.random.permutation(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_function(domain, key):\n",
    "    \n",
    "    embedded_vector = None\n",
    "    \n",
    "    if domain == action_idx[9]:  #'poi'\n",
    "        if key in poi_idx:\n",
    "            idx = poi_idx.index(key)\n",
    "        else:\n",
    "            idx = 0\n",
    "        embedded_vector = tf.nn.embedding_lookup(poi_embedding, idx)\n",
    "        \n",
    "    elif (domain == action_idx[1])|(domain == action_idx[3])|(domain == action_idx[4])|(domain == action_idx[5])\\\n",
    "    |(domain == action_idx[6])|(domain == action_idx[8]):  #impression\n",
    "        if key in impressions_idx:\n",
    "            idx = impressions_idx.index(key)\n",
    "        else:\n",
    "            idx = 0\n",
    "        embedded_vector = tf.nn.embedding_lookup(impression_embedding, idx)\n",
    "    \n",
    "    elif domain == action_idx[7]: # search for destination, 'city'\n",
    "        if key in city_idx:\n",
    "            idx = city_idx.index(key)\n",
    "        else:\n",
    "            idx = 0\n",
    "        embedded_vector = tf.nn.embedding_lookup(city_embedding, idx)\n",
    "\n",
    "    elif domain == 'platform':\n",
    "        if key in platform_idx:\n",
    "            idx = platform_idx.index(key)\n",
    "        else:\n",
    "            idx = 0\n",
    "        embedded_vector = tf.nn.embedding_lookup(platform_embedding, idx)\n",
    "        \n",
    "    elif domain ==action_idx[2]:  #'filter'\n",
    "        if key in filter_idx:\n",
    "            idx = filter_idx.index(key)\n",
    "        else:\n",
    "            idx = 0\n",
    "        embedded_vector = tf.nn.embedding_lookup(filter_embedding, idx)\n",
    "        \n",
    "    elif domain ==action_idx[0]:  #sorting\n",
    "        embedded_vector = np.zeros([sort_embed_size])\n",
    "        embedded_vector[sort_order_idx.index(key)] = 1\n",
    "        embedded_vector = tf.convert_to_tensor(embedded_vector, dtype=tf.float32)\n",
    "        \n",
    "    elif domain =='device':\n",
    "        embedded_vector = np.zeros([device_embed_size])\n",
    "        embedded_vector[device_idx.index(key)] = 1\n",
    "        embedded_vector = tf.convert_to_tensor(embedded_vector, dtype=tf.float32)\n",
    "        \n",
    "    return embedded_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change of sort order',\n",
       " 'clickout item',\n",
       " 'filter selection',\n",
       " 'interaction item deals',\n",
       " 'interaction item image',\n",
       " 'interaction item info',\n",
       " 'interaction item rating',\n",
       " 'search for destination',\n",
       " 'search for item',\n",
       " 'search for poi']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_embedding(action):\n",
    "    if action == action_idx[0]:\n",
    "        embed = tf.one_hot(0, 5)\n",
    "    elif action == action_idx[2]:\n",
    "        embed = tf.one_hot(1, 5)\n",
    "    elif action == action_idx[7]:\n",
    "        embed = tf.one_hot(2, 5)\n",
    "    elif action == action_idx[9]:\n",
    "        embed = tf.one_hot(3, 5)\n",
    "    else:\n",
    "        embed = tf.one_hot(4, 5)\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequenceData(act_list, ref_list, seq_length):\n",
    "    embed_total = tf.zeros([1, seq_length, rnn_input_size])  #추후 1 -> batch size 변경\n",
    "    for step in range(np.shape(act_list)[1]): \n",
    "        embed_ref = embedding_function(act_list[step], ref_list[step])\n",
    "        embed_action = action_embedding(act_list[step])\n",
    "        embed_total[:,step,:] = tf.concat((embed_action, embed_ref), axis=0)\n",
    "    return embed_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActionList(user_label, seq_length):\n",
    "    step = user_label['step']\n",
    "    if step > seq_length+1:\n",
    "        step = seq_length+1\n",
    "    label_point = user_label.name\n",
    "    history_list = train_df[label_point-step+1:label_point]\n",
    "    \n",
    "    act_list=[]\n",
    "    ref_list=[]\n",
    "    for idx in range(len(history_list)):\n",
    "        act_list.append(history_list.iloc[idx]['action_type'])\n",
    "        ref_list.append(history_list.iloc[idx]['reference'])\n",
    "    if len(act_list) < seq_length:\n",
    "        act_list = np.concatenate((np.zeros([seq_length-len(act_list)]), act_list))\n",
    "        ref_list = np.concatenate((np.zeros([seq_length-len(ref_list)]), ref_list))\n",
    "    \n",
    "    return np.reshape(act_list, [-1, seq_length]), np.reshape(ref_list, [-1, seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_neural_network_model(act_list_batch, ref_list_batch):\n",
    "    \n",
    "    XX = getSequenceData(Act_list, Ref_list, seq_length)\n",
    "\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_state_size)    \n",
    "    outputs, states = tf.nn.dynamic_rnn(lstm_cell, XX, dtype=tf.float32)   \n",
    "    \n",
    "    return outputs, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def context_LSTM_net(act_list_batch, ref_list_batch):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(XX_input, n_hidden_1,activation=tf.nn.relu)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2,activation=tf.nn.relu)\n",
    "#     layer_2_dropout = tf.layers.dropout(layer2, training=True)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    layer_3 = tf.layers.dense(layer_2, n_hidden_3, activation=tf.nn.relu)\n",
    "    out_layer = tf.layers.dense(layer_3, 1, activation=tf.nn.sigmoid)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = None\n",
    "for k in range(3):\n",
    "    idx = batch_indexes[k*batch_size:(k+1)*batch_size]\n",
    "    label_df = train_label.iloc[idx]\n",
    "    for i in range(3):  # batch size\n",
    "        user_label = label_df.iloc[i]\n",
    "        train_label_batch = user_label[\"reference\"]  # 클릭한 reference number\n",
    "        train_candidates = user_label['impressions']\n",
    "        train_candidates = f.string_to_array(train_candidates)   \n",
    "        \n",
    "        candidate_prices = user_label['prices']\n",
    "        candidate_prices = f.string_to_array(candidate_prices)\n",
    "        candidate_prices = np.array(candidate_prices).astype(int)\n",
    "        \n",
    "        act_list, ref_list = getActionList(user_label, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=1\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    idx = batch_indexes[k*batch_size:(k+1)*batch_size]\n",
    "    label_df = train_label.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "        user_label = label_df.iloc[i]\n",
    "        train_label_batch = user_label[\"reference\"]  # 클릭한 reference number\n",
    "        train_candidates = user_label['impressions']\n",
    "        train_candidates = f.string_to_array(train_candidates)   \n",
    "        \n",
    "        candidate_prices = user_label['prices']\n",
    "        candidate_prices = f.string_to_array(candidate_prices)\n",
    "        candidate_prices = np.array(candidate_prices).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                                                 E8L9VGGZJJB2\n",
       "session_id                                             3498d5bcec072\n",
       "timestamp                                                 1541545347\n",
       "step                                                              11\n",
       "action_type                                            clickout item\n",
       "reference                                                      85097\n",
       "platform                                                          UK\n",
       "city                                                 Sorrento, Italy\n",
       "device                                                        tablet\n",
       "current_filters    Best Value|Swimming Pool (Combined Filter)|Air...\n",
       "impressions        1105350|82794|153849|45573|45453|1207105|93578...\n",
       "prices             142|137|129|221|230|145|169|215|135|140|181|25...\n",
       "Name: 1263363, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_list, ref_list = getActionList(user_label, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(np.shape(Act_list)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_list = Act_list\n",
    "ref_list = Ref_list\n",
    "embed_total = tf.zeros([1, seq_length, rnn_input_size])  #추후 1 -> batch size 변경\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "step =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_ref = embedding_function(act_list[step], ref_list[step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_action = action_embedding(act_list[step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was Tensor(\"Placeholder:0\", shape=(?, 10), dtype=string) which was passed to the feed with key Tensor(\"Placeholder:0\", shape=(?, 10), dtype=string).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6080cfc3325b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mAct_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                             \u001b[0;34m'For reference, the tensor object was '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' which was passed to the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                             'feed with key ' + str(feed) + '.')\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m           \u001b[0msubfeed_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles. For reference, the tensor object was Tensor(\"Placeholder:0\", shape=(?, 10), dtype=string) which was passed to the feed with key Tensor(\"Placeholder:0\", shape=(?, 10), dtype=string)."
     ]
    }
   ],
   "source": [
    "sess.run(embed_action, feed_dict={Act_list:action_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"one_hot_2:0\", shape=(5,), dtype=float32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-6ad55ffbec3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1251\u001b[0m       ops.convert_to_tensor(\n\u001b[1;32m   1252\u001b[0m           \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat_dim\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1253\u001b[0;31m           \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1254\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1255\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m   \"\"\"\n\u001b[0;32m-> 1039\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    975\u001b[0m     raise ValueError(\n\u001b[1;32m    976\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    978\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"one_hot_2:0\", shape=(5,), dtype=float32)'"
     ]
    }
   ],
   "source": [
    "tf.concat(embed_ref, embed_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
