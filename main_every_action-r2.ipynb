{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "impression_embed_size = 50 # 853,540개 \n",
    "poi_embed_size = 50      # 13,352개\n",
    "filter_embed_size = 50   # 208개\n",
    "platform_embed_size = 5       # 55개\n",
    "city_embed_size = 50          # 34,752개\n",
    "sort_embed_size = 50 #interaction 빼고 one-hot\n",
    "device_embed_size = 3 # mobile, desktop, tablet one-hot\n",
    "\n",
    "rnn_input_size = impression_embed_size + 5 # action 5개로 통합 후 one-hot \n",
    "\n",
    "global_imp_idx=0\n",
    "#LSTM\n",
    "hidden_state_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "seq_length = 15\n",
    "num_epoch = 10\n",
    "batch_size = 1\n",
    "\n",
    "input_size = 100 # TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functions as f\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "meta_df = pd.read_csv('./item_metadata.csv')\n",
    "submit_df = pd.read_csv('./submission_popular.csv')\n",
    "\n",
    "popular_df = f.get_popularity(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npoi_embedding = tf.get_variable(\"poi_embedding\", [len(poi_idx), poi_embed_size])\\nimpression_embedding = tf.get_variable(\"impression_embedding\", [len(impressions_idx), impression_embed_size])\\ncity_embedding = tf.get_variable(\"city_embedding\", [len(city_idx), city_embed_size])\\nplatform_embedding = tf.get_variable(\"platform_embedding\", [len(platform_idx), platform_embed_size])\\nfilter_embedding = tf.get_variable(\"filter_embedding\", [len(filter_idx), filter_embed_size])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_idx = np.load('./npy/poi_names.npy', allow_pickle=True)\n",
    "poi_idx = list(poi_idx)\n",
    "impressions_idx = np.load('./npy/impressions_index.npy', allow_pickle=True)\n",
    "impressions_idx = list(impressions_idx)\n",
    "city_idx = np.load('./npy/city_names.npy', allow_pickle=True)\n",
    "city_idx = list(city_idx)\n",
    "platform_idx = np.load('./npy/platform_names.npy', allow_pickle=True)\n",
    "platform_idx = list(platform_idx)\n",
    "filter_idx = np.load('./npy/filter_merged.npy', allow_pickle=True)\n",
    "filter_idx = list(filter_idx)\n",
    "action_idx = np.load('./npy/action_type_names.npy', allow_pickle=True)\n",
    "action_idx = list(action_idx)\n",
    "\n",
    "sort_order_idx = np.load('./npy/sorting_names.npy', allow_pickle=True)\n",
    "sort_order_idx = list(sort_order_idx)\n",
    "device_idx = np.load('./npy/device_names.npy', allow_pickle=True)\n",
    "device_idx = list(device_idx)\n",
    "'''\n",
    "poi_embedding = tf.get_variable(\"poi_embedding\", [len(poi_idx), poi_embed_size])\n",
    "impression_embedding = tf.get_variable(\"impression_embedding\", [len(impressions_idx), impression_embed_size])\n",
    "city_embedding = tf.get_variable(\"city_embedding\", [len(city_idx), city_embed_size])\n",
    "platform_embedding = tf.get_variable(\"platform_embedding\", [len(platform_idx), platform_embed_size])\n",
    "filter_embedding = tf.get_variable(\"filter_embedding\", [len(filter_idx), filter_embed_size])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_df[(train_df[\"action_type\"] == \"clickout item\")]     #train_label : (1,586,586, 12)\n",
    "batch_indexes = np.random.permutation(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_function(domain, key):\n",
    "    \n",
    "    embedded_vector = tf.zeros([impression_embed_size])\n",
    "    if domain == action_idx[9]:  #'poi'\n",
    "        if key in poi_idx:\n",
    "            idx = poi_idx.index(key)\n",
    "        else:\n",
    "            idx = -1\n",
    "        embedded_vector = tf.nn.embedding_lookup(poi_embedding, idx)\n",
    "        \n",
    "    elif (domain == action_idx[1])|(domain == action_idx[3])|(domain == action_idx[4])|(domain == action_idx[5])\\\n",
    "    |(domain == action_idx[6])|(domain == action_idx[8]):  #impression\n",
    "        if key in impressions_idx:\n",
    "            idx = impressions_idx.index(key)\n",
    "        else:\n",
    "            idx = -1\n",
    "        embedded_vector = tf.nn.embedding_lookup(impression_embedding, idx)\n",
    "    \n",
    "    elif domain == action_idx[7]: # search for destination, 'city'\n",
    "        if key in city_idx:\n",
    "            idx = city_idx.index(key)\n",
    "        else:\n",
    "            idx = -1\n",
    "        embedded_vector = tf.nn.embedding_lookup(city_embedding, idx)\n",
    "\n",
    "    elif domain == 'platform':\n",
    "        if key in platform_idx:\n",
    "            idx = platform_idx.index(key)\n",
    "        else:\n",
    "            idx = -1\n",
    "        embedded_vector = tf.nn.embedding_lookup(platform_embedding, idx)\n",
    "        \n",
    "    elif domain ==action_idx[2]:  #'filter'\n",
    "        if key in filter_idx:\n",
    "            idx = filter_idx.index(key)\n",
    "        else:\n",
    "            idx = -1\n",
    "        embedded_vector = tf.nn.embedding_lookup(filter_embedding, idx)\n",
    "        \n",
    "    elif domain ==action_idx[0]:  #sorting\n",
    "        embedded_vector = np.zeros([sort_embed_size])\n",
    "        embedded_vector[sort_order_idx.index(key)] = 1\n",
    "        embedded_vector = tf.convert_to_tensor(embedded_vector, dtype=tf.float32)\n",
    "        \n",
    "    elif domain =='device':\n",
    "        embedded_vector = np.zeros([device_embed_size])\n",
    "#         embedded_vector[device_idx.index(key)] = 1\n",
    "        embedded_vector = tf.convert_to_tensor(embedded_vector, dtype=tf.float32)\n",
    "        \n",
    "    return embedded_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change of sort order',\n",
       " 'clickout item',\n",
       " 'filter selection',\n",
       " 'interaction item deals',\n",
       " 'interaction item image',\n",
       " 'interaction item info',\n",
       " 'interaction item rating',\n",
       " 'search for destination',\n",
       " 'search for item',\n",
       " 'search for poi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_embedding(action):\n",
    "    if action == action_idx[0]:\n",
    "        embed = tf.one_hot(0, 5)\n",
    "    elif action == action_idx[2]:\n",
    "        embed = tf.one_hot(1, 5)\n",
    "    elif action == action_idx[7]:\n",
    "        embed = tf.one_hot(2, 5)\n",
    "    elif action == action_idx[9]:\n",
    "        embed = tf.one_hot(3, 5)\n",
    "    else:\n",
    "        embed = tf.one_hot(4, 5)\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_user_id =0                                                 \n",
    "INDEX_session_id =1                                            \n",
    "INDEX_timestamp =2                                                \n",
    "INDEX_step        =3                                                       \n",
    "INDEX_action_type =4                                       \n",
    "INDEX_reference   =5                                               \n",
    "INDEX_platform    =6                                                \n",
    "INDEX_city        =7                                          \n",
    "INDEX_device      =8                                                 \n",
    "INDEX_current_filters=9                                                \n",
    "INDEX_impressions    =10   \n",
    "INDEX_prices         =11    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequenceData(act_list, ref_list, seq_length):\n",
    "    embed_total = tf.zeros([rnn_input_size])  #추후 1 -> batch size 변경\n",
    "    embed_total = tf.reshape(embed_total, [1, rnn_input_size])\n",
    "    for step in range(np.shape(act_list)[1]): \n",
    "        embed_ref = embedding_function(act_list[step], ref_list[step])\n",
    "        embed_action = action_embedding(act_list[step])\n",
    "        \n",
    "        embed_single_action = tf.concat((embed_action, embed_ref), axis=0)\n",
    "        embed_total = tf.concat((embed_total, tf.reshape(embed_single_action, [1,55])), axis=0)\n",
    "        \n",
    "    return embed_total[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActionList(user_label):\n",
    "    step = user_label['step']\n",
    "    if step > seq_length+1:\n",
    "        step = seq_length+1\n",
    "    label_point = user_label.name\n",
    "    history_list = train_df[label_point-step+1:label_point]\n",
    "    \n",
    "    act_list=[]\n",
    "    ref_list=[]\n",
    "    for idx in range(len(history_list)):\n",
    "        act_list.append(history_list.iloc[idx]['action_type'])\n",
    "        ref_list.append(history_list.iloc[idx]['reference'])\n",
    "    if len(act_list) < seq_length:\n",
    "        act_list = np.concatenate((np.zeros([seq_length-len(act_list)]), act_list))\n",
    "        ref_list = np.concatenate((np.zeros([seq_length-len(ref_list)]), ref_list))\n",
    "    \n",
    "    return np.reshape(act_list, [-1, seq_length]), np.reshape(ref_list, [-1, seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_neural_network_model(Act_list, Ref_list):\n",
    "    \n",
    "    XX = getSequenceData(Act_list, Ref_list, seq_length)\n",
    "    XX = tf.reshape(XX, [batch_size,seq_length, rnn_input_size])\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_state_size)    \n",
    "    _ , states = tf.nn.dynamic_rnn(lstm_cell, XX, dtype=tf.float32)   \n",
    "    \n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_net(context, train_label):\n",
    "     \n",
    "    context = tf.reshape(context, [hidden_state_size])\n",
    "        #platform\n",
    "    \n",
    "    if global_imp_idx in impressions_idx:\n",
    "        idx = impressions_idx.index(global_imp_idx)\n",
    "    else:\n",
    "        idx = -1\n",
    "    target_impression_embed = tf.nn.embedding_lookup(impression_embedding, idx)\n",
    "    \n",
    "        \n",
    "    #platform_embed = embedding_function('platform', train_label[-1,INDEX_platform])\n",
    "    key = train_label[-1,INDEX_platform]\n",
    "    if key in platform_idx:\n",
    "        idx = platform_idx.index(key)\n",
    "    else:\n",
    "        idx = 0\n",
    "    platform_embed = tf.nn.embedding_lookup(platform_embedding, idx)\n",
    "    #city, search for destination 해서 검색해봤던 city들\n",
    "    #city_embed = embedding_function('city', train_label[-1,INDEX_city])\n",
    "    key = train_label[-1,INDEX_city]\n",
    "    if key in city_idx:\n",
    "        idx = city_idx.index(key)\n",
    "    else:\n",
    "        idx = 0\n",
    "    city_embed = tf.nn.embedding_lookup(city_embedding, idx)\n",
    "    #device\n",
    "    #device_embed = embedding_function('device', train_label[-1,INDEX_device])\n",
    "    key = train_label[-1,INDEX_device]\n",
    "    device_embed = np.zeros([device_embed_size])\n",
    "#         embedded_vector[device_idx.index(key)] = 1\n",
    "    device_embed= tf.convert_to_tensor(device_embed, dtype=tf.float32)\n",
    "    #current_filter\n",
    "    \n",
    "    filter_b = train_label[-1,INDEX_current_filters]\n",
    "    if pd.isna(filter_b):\n",
    "        final_embed_current_filter = tf.zeros(filter_embed_size)\n",
    "    else:\n",
    "        final_embed_current_filter = tf.zeros(filter_embed_size)\n",
    "#         filters_b = f.string_to_array(filter_b)\n",
    "#         final_embed_current_filter = getWeightedAverage('filter', filters_b , filter_embed_size)\n",
    "    \n",
    "#     print(\"context\", np.shape(context))\n",
    "#     print(\"platform_embed\", np.shape(platform_embed))\n",
    "#     print(\"city_embed\", np.shape(city_embed))\n",
    "#     print(\"device_embed\", np.shape(device_embed))\n",
    "    \n",
    "    XX_input= tf.concat((context, platform_embed, city_embed, device_embed, target_impression_embed),axis=0)\n",
    "    \n",
    "    XX_input = tf.reshape(XX_input, [-1, 236])\n",
    "    layer_1 = tf.layers.dense(XX_input, 256,activation=tf.nn.relu)\n",
    "    layer_2 = tf.layers.dense(layer_1, 128,activation=tf.nn.relu)\n",
    "    layer_3 = tf.layers.dense(layer_2, 64, activation=tf.nn.relu)\n",
    "    out_layer = tf.layers.dense(layer_3, 1)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ecube_server2/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network\n",
    "tf.reset_default_graph()\n",
    "Act_list = tf.placeholder(tf.string, [None, seq_length])\n",
    "Ref_list = tf.placeholder(tf.string, [None, seq_length])\n",
    "\n",
    "Train_Label_df = tf.placeholder(tf.string, [None, 12])\n",
    "Y_label = tf.placeholder(tf.float32, [None, 1])\n",
    "Learing_Rate_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "poi_embedding = tf.get_variable(\"poi_embedding\", [len(poi_idx), poi_embed_size])\n",
    "impression_embedding = tf.get_variable(\"impression_embedding\", [len(impressions_idx), impression_embed_size])\n",
    "city_embedding = tf.get_variable(\"city_embedding\", [len(city_idx), city_embed_size])\n",
    "platform_embedding = tf.get_variable(\"platform_embedding\", [len(platform_idx), platform_embed_size])\n",
    "filter_embedding = tf.get_variable(\"filter_embedding\", [len(filter_idx), filter_embed_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-1dd4d4c0f6f3>:5: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-14-1dd4d4c0f6f3>:6: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-15-86a9d7b6716d>:52: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/ecube_server2/.conda/envs/recsys/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "context = recurrent_neural_network_model(Act_list, Ref_list)\n",
    "output = dense_net(context[0], Train_Label_df)\n",
    "# loss = tf.losses.sigmoid_cross_entropy(Y_label, output)\n",
    "# loss = tf.losses.mean_squared_error(Y_label, output)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y_label, logits=output)\n",
    "train = tf.train.AdamOptimizer(learning_rate=Learing_Rate_ph).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1586586"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3e183c90b992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlabel_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2219\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2198\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m             \u001b[0;31m# re-raise with different error message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3359\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 1350\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1238\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64tz_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeTZDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/recsys/lib/python3.6/site-packages/pandas/core/dtypes/base.py\u001b[0m in \u001b[0;36mis_dtype\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m            \u001b[0mconditions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         if isinstance(dtype, (ABCSeries, ABCIndexClass,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "label_df = None\n",
    "for epoch in range(5):\n",
    "    for k in range(len(train_label)):\n",
    "        idx = batch_indexes[k*batch_size:(k+1)*batch_size]\n",
    "        label_df = train_label.iloc[idx]\n",
    "        try:\n",
    "            for i in range(1):  # batch size\n",
    "                user_label = label_df.iloc[i]\n",
    "                train_label_batch = user_label[\"reference\"]  # 클릭한 reference number\n",
    "                train_candidates = user_label['impressions']\n",
    "                train_candidates = f.string_to_array(train_candidates)   \n",
    "\n",
    "                candidate_prices = user_label['prices']\n",
    "                candidate_prices = f.string_to_array(candidate_prices)\n",
    "                candidate_prices = np.array(candidate_prices).astype(int)\n",
    "\n",
    "                label_index = train_candidates.index(train_label_batch)\n",
    "                labels = np.zeros([len(train_candidates)],dtype=np.float32)\n",
    "                labels[label_index]=1.0\n",
    "\n",
    "                act_list, ref_list = getActionList(user_label)\n",
    "                act_list = act_list.astype(str)\n",
    "                ref_list = ref_list.astype(str)\n",
    "\n",
    "                user_label = user_label.fillna('Nope')\n",
    "                users = np.array(user_label)\n",
    "                users= np.reshape(users,[-1,12])     \n",
    "                users = users.astype(str)\n",
    "\n",
    "                for h in range(len(train_candidates)):\n",
    "                    global_imp_idx = np.reshape(int(train_candidates[h]))\n",
    "                    print(\"global_imp_idx :\", global_imp_idx)\n",
    "                    if labels[h]==1:\n",
    "                            _  = sess.run([train], feed_dict={Act_list: act_list, Ref_list: ref_list, Train_Label_df: users,\\\n",
    "                                                         Y_label:np.reshape(labels[h],[-1,1]), \\\n",
    "                                                             Learing_Rate_ph: learning_rate*35.0})\n",
    "\n",
    "                            if k%50==0:\n",
    "                                loss_val = sess.run([loss], feed_dict={Act_list: act_list, Ref_list: ref_list, Train_Label_df: users,\\\n",
    "                                                             Y_label:np.reshape(labels[h],[-1,1])})\n",
    "                                print('epoch: ', epoch, 'step: ', k , \"labels[h]==1 loss : \", loss_val)\n",
    "                                saver.save(sess, './saves/1/my-model.ckpt', global_step=k)\n",
    "                    else:\n",
    "                            _, loss_val = sess.run([train, loss], feed_dict={Act_list: act_list, Ref_list: ref_list, Train_Label_df: users,\\\n",
    "                                                         Y_label:np.reshape(labels[h],[-1,1]), \\\n",
    "                                                                            Learing_Rate_ph: learning_rate})\n",
    "                            if k%50==0:\n",
    "                                if h%10==0:\n",
    "                                    print('epoch: ', epoch, 'step: ',k, \"labels[h]==0 loss : \", loss_val)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getActionListTest(user_label):\n",
    "    step = user_label['step']\n",
    "    if step > seq_length+1:\n",
    "        step = seq_length+1\n",
    "    label_point = user_label.name\n",
    "    history_list = test_df[label_point-step+1:label_point]\n",
    "    \n",
    "    act_list=[]\n",
    "    ref_list=[]\n",
    "    for idx in range(len(history_list)):\n",
    "        act_list.append(history_list.iloc[idx]['action_type'])\n",
    "        ref_list.append(history_list.iloc[idx]['reference'])\n",
    "    if len(act_list) < seq_length:\n",
    "        act_list = np.concatenate((np.zeros([seq_length-len(act_list)]), act_list))\n",
    "        ref_list = np.concatenate((np.zeros([seq_length-len(ref_list)]), ref_list))\n",
    "    \n",
    "    return np.reshape(act_list, [-1, seq_length]), np.reshape(ref_list, [-1, seq_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_TestSet(user_label):\n",
    "    for i in range(1):  \n",
    "#         user_label = label_df.iloc[i]\n",
    "        train_candidates = user_label['impressions']\n",
    "        train_candidates = f.string_to_array(train_candidates)   \n",
    "\n",
    "        candidate_prices = user_label['prices']\n",
    "        candidate_prices = f.string_to_array(candidate_prices)\n",
    "        candidate_prices = np.array(candidate_prices).astype(int)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        act_list, ref_list = getActionListTest(user_label)\n",
    "        act_list = act_list.astype(str)\n",
    "        ref_list = ref_list.astype(str)\n",
    "        \n",
    "        user_label = user_label.fillna('Nope')\n",
    "        users = np.array(user_label)\n",
    "        users = users.astype(str)\n",
    "        users= np.reshape(users,[-1,12])     \n",
    "\n",
    "        for h in range(len(train_candidates)):\n",
    "            prediction = sess.run(output, feed_dict={Act_list: act_list, Ref_list: ref_list, Train_Label_df: users,\\\n",
    "                                                             Target_impression: np.reshape(int(train_candidates[h]),[-1,1])})\n",
    "            predictions.append(prediction)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_TrainSet(user_label):\n",
    "    for i in range(1):  \n",
    "#         user_label = label_df.iloc[i]\n",
    "        train_candidates = user_label['impressions']\n",
    "        train_candidates = f.string_to_array(train_candidates)   \n",
    "\n",
    "        candidate_prices = user_label['prices']\n",
    "        candidate_prices = f.string_to_array(candidate_prices)\n",
    "        candidate_prices = np.array(candidate_prices).astype(int)\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        act_list, ref_list = getActionList(user_label)\n",
    "        act_list = act_list.astype(str)\n",
    "        ref_list = ref_list.astype(str)\n",
    "        \n",
    "        user_label = user_label.fillna('Nope')\n",
    "        users = np.array(user_label)\n",
    "        users = users.astype(str)\n",
    "        users= np.reshape(users,[-1,12])     \n",
    "\n",
    "        for h in range(len(train_candidates)):\n",
    "            prediction = sess.run(output, feed_dict={Act_list: act_list, Ref_list: ref_list, Train_Label_df: users,\\\n",
    "                                                             Target_impression: np.reshape(int(train_candidates[h]),[-1,1])})\n",
    "            predictions.append(prediction)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_TrainSet(train_label.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    idx = batch_indexes[k*batch_size:(k+1)*batch_size]\n",
    "    label_df = train_label.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        user_label = label_df.iloc[i]\n",
    "        train_label_batch = user_label[\"reference\"]  # 클릭한 reference number\n",
    "        train_candidates = user_label['impressions']\n",
    "        train_candidates = f.string_to_array(train_candidates)   \n",
    "        \n",
    "        candidate_prices = user_label['prices']\n",
    "        candidate_prices = f.string_to_array(candidate_prices)\n",
    "        candidate_prices = np.array(candidate_prices).astype(int)\n",
    "        \n",
    "        label_index = train_candidates.index(train_label_batch)\n",
    "        labels = np.zeros([len(train_candidates)],dtype=int)\n",
    "        labels[label_index]=1\n",
    "        \n",
    "        act_list, ref_list = getActionList(user_label)\n",
    "        act_list = act_list.astype(str)\n",
    "        ref_list = ref_list.astype(str)\n",
    "        \n",
    "        user_label = user_label.fillna('Nope')\n",
    "        users = np.array(user_label)\n",
    "        users= np.reshape(users,[-1,12])     \n",
    "        users = users.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_impression = np.reshape(int(train_candidates[0]),[-1,1])\n",
    "if target_impression in impressions_idx:\n",
    "    idx = impressions_idx.index(target_impression)\n",
    "else:\n",
    "    idx = -1\n",
    "print('idx :', idx)\n",
    "target_impression_embed = tf.nn.embedding_lookup(impression_embedding, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(target_impression_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sess.run(output, feed_dict={Act_list: act_list, Ref_list: ref_list, Train_Label_df: users,\\\n",
    "                                         Target_impression: np.reshape(int(train_candidates[0]),[-1,1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
